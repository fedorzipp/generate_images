import streamlit as st
from diffusers import StableDiffusionPipeline
import torch
import openai
import base64
from PIL import Image
from io import BytesIO

# --- OpenAI API key ---
openai.api_key = "YOUR_API_KEY"  # ‚ö†Ô∏è –∑–∞–º—ñ–Ω–∏ –Ω–∞ —Å–≤—ñ–π –∫–ª—é—á

# --- Stable Diffusion init ---
@st.cache_resource
def load_sd_model():
    model_id = "runwayml/stable-diffusion-v1-5"
    pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)
    pipe = pipe.to("cuda" if torch.cuda.is_available() else "cpu")
    return pipe

pipe = load_sd_model()

st.title("üé® Pipeline: Stable Diffusion ‚Üí OpenAI API")

prompt = st.text_area("–í–≤–µ–¥—ñ—Ç—å –æ–ø–∏—Å (prompt):", "A fantasy castle on a mountain at sunset")

if st.button("–ó–∞–ø—É—Å—Ç–∏—Ç–∏ Pipeline"):
    # Step 1: SD –≥–µ–Ω–µ—Ä—É—î –±–∞–∑–æ–≤—É –∫–∞—Ä—Ç–∏–Ω–∫—É
    with st.spinner("Stable Diffusion –≥–µ–Ω–µ—Ä—É—î —á–æ—Ä–Ω–æ–≤–∏–∫..."):
        sd_image = pipe(prompt).images[0]
        st.image(sd_image, caption="Stable Diffusion (—á–æ—Ä–Ω–æ–≤–∏–∫)")

        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —É –±–∞–π—Ç–∏
        buffer = BytesIO()
        sd_image.save(buffer, format="PNG")
        sd_bytes = buffer.getvalue()

    # Step 2: OpenAI —Ä–æ–±–∏—Ç—å variation (–ø–æ–∫—Ä–∞—â–µ–Ω–∞ –≤–µ—Ä—Å—ñ—è)
    with st.spinner("OpenAI API –ø–æ–∫—Ä–∞—â—É—î –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è..."):
        response = openai.images.variations(
            model="gpt-image-1",  # DALL¬∑E 3
            image=sd_bytes,
            size="512x512"
        )
        image_base64 = response.data[0].b64_json
        image_bytes = base64.b64decode(image_base64)
        openai_image = Image.open(BytesIO(image_bytes))

        st.image(openai_image, caption="OpenAI API (–ø–æ–∫—Ä–∞—â–µ–Ω–∞ –≤–µ—Ä—Å—ñ—è)")
